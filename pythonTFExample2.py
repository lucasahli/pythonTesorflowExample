# mlp for the circles problem with cross entropy loss
# from sklearn.datasets import make_circles
import keras.models
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
# from keras.optimizers import SGD
import tensorflow as tf
from matplotlib import pyplot
from numpy import genfromtxt
import numpy as np


goodAPoses = genfromtxt('/Users/luca/Desktop/workingDirectory/previewImages/unsorted/good/poses.csv', delimiter=',')
badAPoses = genfromtxt('/Users/luca/Desktop/workingDirectory/previewImages/unsorted/bad/poses.csv', delimiter=',')

labelsGood = np.ones([goodAPoses.shape[0]], dtype=np.int32)
labelsBad = np.zeros([badAPoses.shape[0]], dtype=np.int32)

X = np.concatenate((goodAPoses, badAPoses), axis=0)
Y = np.concatenate((labelsGood, labelsBad), axis=0)
Y = Y[:, np.newaxis]

DATA = np.concatenate((X, Y), axis=-1)
np.random.shuffle(DATA)

X = DATA[:, :-1]
Y = DATA[:, -1]
# generate 2d classification dataset
# X, y = make_circles(n_samples=1000, noise=0.1, random_state=1)
# split into train and test
n_train = 1200
trainX, testX = X[:n_train, :], X[n_train:, :]
trainy, testy = Y[:n_train], Y[n_train:]
# define model
model = Sequential()
model.add(Dense(136, input_dim=34, activation='relu', kernel_initializer='he_uniform'))
model.add(Dropout(0.5))
model.add(Dense(68, activation='relu', kernel_initializer='he_uniform'))
model.add(Dense(34, activation='relu', kernel_initializer='he_uniform'))
model.add(Dense(17, activation='relu', kernel_initializer='he_uniform'))
model.add(Dense(1, activation='sigmoid'))
opt = tf.keras.optimizers.Adam(lr=0.0002) #SGD(lr=0.01, momentum=0.9)
model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])
# fit model
history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=600, batch_size=10, verbose=0)
# evaluate the model
_, train_acc = model.evaluate(trainX, trainy, verbose=0)
_, test_acc = model.evaluate(testX, testy, verbose=0)
print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))
# plot loss during training
pyplot.subplot(211)
pyplot.title('Loss')
pyplot.plot(history.history['loss'], label='train')
pyplot.plot(history.history['val_loss'], label='test')
pyplot.legend()
# plot accuracy during training
pyplot.subplot(212)
pyplot.title('Accuracy')
pyplot.plot(history.history['accuracy'], label='train')
pyplot.plot(history.history['val_accuracy'], label='test')
pyplot.legend()
pyplot.show()

# Test
goodAPose = np.array([0.101318,0.491829,0.0852958,0.511805,0.0841727,0.471087,0.106221,0.534901,0.102035,0.447689,0.214236,0.577794,0.205027,0.401328,0.307764,0.69233,0.296297,0.276292,0.38414,0.789242,0.369121,0.182343,0.478153,0.548575,0.479801,0.430937,0.712054,0.564377,0.709802,0.417897,0.900895,0.570023,0.907556,0.407681])

good = np.array([[0.101318,0.491829,0.0852958,0.511805,0.0841727,0.471087,0.106221,0.534901,0.102035,0.447689,0.214236,0.577794,0.205027,0.401328,0.307764,0.69233,0.296297,0.276292,0.38414,0.789242,0.369121,0.182343,0.478153,0.548575,0.479801,0.430937,0.712054,0.564377,0.709802,0.417897,0.900895,0.570023,0.907556,0.407681],
                 [0.109918,0.496317,0.0923036,0.515046,0.0931972,0.473661,0.115645,0.538353,0.114501,0.449094,0.228043,0.596885,0.2292,0.409521,0.361522,0.650416,0.364371,0.346027,0.460788,0.711588,0.471653,0.279231,0.484143,0.550474,0.48616,0.4462,0.697034,0.558546,0.696754,0.438094,0.890874,0.57009,0.897726,0.433255],
[0.125746,0.49696,0.104962,0.517677,0.105717,0.475845,0.124067,0.541439,0.124658,0.448925,0.225379,0.592792,0.224755,0.398631,0.354259,0.658872,0.349378,0.322976,0.444035,0.749474,0.448199,0.235943,0.489616,0.553203,0.493529,0.424752,0.71011,0.580607,0.710035,0.401994,0.905076,0.637687,0.90665,0.342449],
[0.0894161,0.477326,0.0779287,0.495079,0.0816146,0.458881,0.109798,0.525117,0.112185,0.436638,0.213186,0.577194,0.213099,0.37762,0.345261,0.654211,0.355006,0.302237,0.447289,0.75494,0.468114,0.207618,0.483592,0.543098,0.484733,0.41014,0.701172,0.550965,0.720821,0.374886,0.883057,0.603816,0.93492,0.322874],
[0.096419,0.486937,0.080252,0.507002,0.0849555,0.465345,0.110411,0.538264,0.116681,0.443328,0.217004,0.597245,0.233223,0.402185,0.357359,0.69575,0.381278,0.31906,0.459333,0.790254,0.491328,0.23574,0.484548,0.568716,0.488028,0.432657,0.713061,0.578673,0.701648,0.42864,0.90286,0.609088,0.914644,0.405189],
[0.0955745,0.49023,0.0797463,0.50923,0.0796626,0.468007,0.0996021,0.536289,0.102967,0.447221,0.202936,0.584443,0.201231,0.406724,0.33395,0.666244,0.350992,0.330825,0.430651,0.756142,0.45445,0.230257,0.468808,0.555285,0.469531,0.435596,0.694458,0.560875,0.690757,0.425914,0.889289,0.597651,0.887038,0.392037],
[0.0999222,0.490815,0.0850091,0.510422,0.087841,0.46881,0.109586,0.531831,0.111177,0.449202,0.214125,0.584489,0.217286,0.408214,0.35511,0.637826,0.369211,0.353262,0.457843,0.72128,0.478499,0.281194,0.483167,0.552334,0.484679,0.435629,0.697362,0.5666,0.703247,0.428343,0.89326,0.593975,0.892672,0.396196],
[0.100484,0.490575,0.0844621,0.509661,0.0852827,0.470736,0.104644,0.529177,0.103562,0.449203,0.219483,0.57852,0.217791,0.403576,0.355122,0.634274,0.360452,0.344674,0.456156,0.701125,0.466333,0.277445,0.485031,0.539905,0.48124,0.429698,0.715804,0.565064,0.719846,0.428207,0.899077,0.576514,0.906561,0.406464],
[0.127272,0.48607,0.108873,0.505667,0.109943,0.465602,0.120928,0.530883,0.118963,0.439706,0.217629,0.579654,0.218032,0.383947,0.341807,0.66562,0.346546,0.322221,0.415363,0.733713,0.447211,0.232341,0.488027,0.542879,0.490082,0.424898,0.712773,0.564828,0.714236,0.412228,0.891163,0.596462,0.888862,0.387047]])

for pose in range(0, good.shape[0]):
  a = good[pose, :][np.newaxis, :]
  print(pose, model.predict(a))
  print("---- ----- -----")

bad = np.array([[0.0855109,0.488726,0.0764183,0.507854,0.075791,0.470685,0.106666,0.533184,0.104461,0.45109,0.210827,0.58181,0.220695,0.417511,0.347723,0.630027,0.350974,0.381943,0.457796,0.6642,0.451945,0.327834,0.475397,0.556228,0.474085,0.431436,0.713491,0.579555,0.707039,0.404139,0.911279,0.60715,0.896295,0.384118],
[0.0938362,0.480719,0.0843816,0.500589,0.0787341,0.463448,0.107985,0.521773,0.107607,0.434679,0.21024,0.564631,0.21434,0.384219,0.335415,0.640964,0.361322,0.317906,0.421498,0.724728,0.455213,0.243166,0.480763,0.537407,0.484488,0.422673,0.693912,0.547161,0.69791,0.43531,0.867572,0.55916,0.888966,0.429812],
[0.127695,0.495724,0.114822,0.515117,0.112959,0.479306,0.144379,0.535678,0.13846,0.454894,0.245038,0.589452,0.251342,0.409146,0.38452,0.654819,0.384254,0.349294,0.496089,0.676141,0.504417,0.311287,0.512723,0.559306,0.51454,0.430665,0.722813,0.560938,0.725494,0.42362,0.906907,0.578741,0.901249,0.399265],
[0.117572,0.491134,0.0986352,0.507983,0.0980976,0.469477,0.10298,0.532192,0.105213,0.446516,0.204173,0.587321,0.207092,0.393105,0.354795,0.642291,0.357585,0.348343,0.475372,0.678635,0.472055,0.315415,0.474641,0.555264,0.474055,0.42461,0.696,0.574254,0.692519,0.408435,0.887786,0.600579,0.880988,0.39232],
[0.0967098,0.503704,0.0846741,0.524912,0.0776222,0.486287,0.108062,0.541356,0.103245,0.451483,0.226604,0.590661,0.226356,0.39067,0.367419,0.650659,0.385286,0.333763,0.497305,0.688418,0.512671,0.301122,0.489687,0.553947,0.491237,0.438743,0.71369,0.547438,0.702299,0.444183,0.89996,0.569771,0.894556,0.433529],
[0.0922226,0.493287,0.0813141,0.509418,0.0804499,0.475142,0.108985,0.535092,0.10739,0.452324,0.213993,0.593474,0.219288,0.402026,0.370287,0.62341,0.371581,0.369621,0.499066,0.634238,0.49952,0.356555,0.487837,0.552611,0.491592,0.438742,0.700208,0.552499,0.705605,0.438789,0.885988,0.552656,0.891935,0.440245],
[0.111023,0.485611,0.0924038,0.50786,0.0917,0.463519,0.105153,0.536226,0.108801,0.442597,0.208788,0.602074,0.215527,0.385798,0.353624,0.646712,0.357524,0.338777,0.464508,0.691051,0.472973,0.279095,0.494426,0.568302,0.495789,0.418624,0.716319,0.602911,0.700953,0.369007,0.910714,0.647973,0.901627,0.322094],
[0.108381,0.4917,0.0925479,0.512392,0.0916568,0.46877,0.117012,0.536028,0.112692,0.446868,0.222277,0.578511,0.227748,0.401837,0.344431,0.669883,0.342314,0.307606,0.429266,0.764874,0.420561,0.210141,0.492144,0.547399,0.490544,0.431543,0.71231,0.558322,0.707071,0.434022,0.887289,0.56017,0.888999,0.436036],
[0.0944506,0.497238,0.0801652,0.514087,0.0794054,0.477167,0.106243,0.537125,0.103908,0.450619,0.216216,0.587593,0.215787,0.401358,0.36497,0.618401,0.365941,0.36593,0.489701,0.652374,0.490524,0.340184,0.487218,0.552443,0.488776,0.429667,0.694278,0.562646,0.698293,0.430887,0.890856,0.575359,0.885652,0.423432],
[0.0993213,0.490108,0.0815764,0.509801,0.0806435,0.471501,0.103212,0.53957,0.0997906,0.451818,0.216694,0.586937,0.214227,0.410515,0.332181,0.698261,0.33643,0.306363,0.424767,0.787678,0.417565,0.202641,0.48307,0.541675,0.480054,0.43749,0.713679,0.577119,0.710029,0.409096,0.901163,0.626734,0.912928,0.355404]])

for pose in range(0, bad.shape[0]):
  a = bad[pose, :][np.newaxis, :]
  print(pose, model.predict(a))
  print("---- ----- -----")

badAPose = np.array([0.0855109,0.488726,0.0764183,0.507854,0.075791,0.470685,0.106666,0.533184,0.104461,0.45109,0.210827,0.58181,0.220695,0.417511,0.347723,0.630027,0.350974,0.381943,0.457796,0.6642,0.451945,0.327834,0.475397,0.556228,0.474085,0.431436,0.713491,0.579555,0.707039,0.404139,0.911279,0.60715,0.896295,0.384118])
a1 = goodAPose[np.newaxis, :]
a2 = badAPose[np.newaxis, :]
print(model.predict(a1))
print(model.predict(a2))

# Convert the model to TFLite
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save the model.
with open('myModel.tflite', 'wb') as f:
  f.write(tflite_model)
print("Wrote myModel.tflite")